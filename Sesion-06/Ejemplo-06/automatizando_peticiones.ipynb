{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 6: Automatizando peticiones\n",
    "\n",
    "### 1. Objetivos:\n",
    "    - Usar todo lo que aprendimos para automatizar peticiones al API\n",
    "    - Guardar nuestros resultados en un archivo tipo .csv\n",
    " \n",
    "---\n",
    "    \n",
    "### 2. Desarrollo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo usar todo lo que aprendimos para automatizar el proceso de realizar múltiples peticiones a la API, reunirlas en un `DataFrame` y guardarlo en un .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.nasa.gov/neo/rest/v1/neo/browse/'\n",
    "parametros = {\n",
    "    'api_key': 'EtSDBzChRyQL87tRvf6vAemUDFCJujscffspj9i5'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener 10 páginas de datos del API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionarios = []\n",
    "for i in range(10):\n",
    "    resultados = requests.get(url, params=parametros)\n",
    "    if resultados.status_code == 200:\n",
    "        datos = resultados.json()\n",
    "        objetos = datos[\"near_earth_objects\"]\n",
    "        diccionarios.append(objetos)\n",
    "        url = datos[\"links\"][\"next\"]\n",
    "        parametros = {}\n",
    "        print(datos[\"links\"][\"self\"])\n",
    "    else:\n",
    "        print(\"Error al obtener la página!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valiando la cantidad de diccionarios obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diccionarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validando el tipo de dato del elemento 0 de la lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(diccionarios[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar y crea los dataframes usando `map` o listas de compresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.json_normalize(d) for d in diccionarios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valida el tipo de dato del elemento 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dfs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explora el inicio del dataframe del elemento 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatena los dataframes en un sólo dataframe y reinicia índices (por alguna buena razón hemos creado una lista de dataframes ¿cierto?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos la cantidad de objetos en el dataframe final, 10 páginas con 20 objetos cada una:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.reset_index(drop=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda tu dataframe en el archivo `objetos_tierra_nasa.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(\"objetos_tierra_nasa.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reto 6: Automatizando peticiones\n",
    "\n",
    "### 1. Objetivos:\n",
    "    - Automatizar la petición de datos a la API de la NASA por fechas.\n",
    " \n",
    "---\n",
    "    \n",
    "### 2. Desarrollo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Automatizando peticiones\n",
    "\n",
    "En el primer Reto realizaste una petición a la API de la NASA para pedir 5 datos de la hoja #100. Ahora, vamos a automatizar el proceso de realizar peticiones a la API para obtener una cantidad bastante mayor de datos.\n",
    "\n",
    "Vamos a obtener ahora los datos por fechas, así que tendrás que ir a la página de la [api de la NASA](https://api.nasa.gov/), para revisar cómo es posible realizar peticiones por fecha. Queremos obtener los **dos primeros meses (Enero y Febrero) del año 1995**. Observa que la API sólo permite peticiones por fecha en rangos de 7 días.\n",
    "\n",
    "Tu reto tiene los siguientes pasos:\n",
    "\n",
    "1. Revisa la documentación de la API de la NASA para entender cómo realizar peticiones por fecha.\n",
    "2. Realiza una primera petición de prueba para entender el formato de los datos que obtienes de regreso (cómo extraemos los datos que necesitamos y qué estructura tienen).\n",
    "2. Escribe el código necesario para automatizar las peticiones a la API y obtener los meses de Enero y Febrero del año 1995.\n",
    "3. Almacena los datos de cada petición y luego usa esos datos para crear `DataFrames`.\n",
    "4. Concatena verticalmente tus `DataFrames` para obtener un `DataFrame` final que contenga todos los datos de tus peticiones. Cada fila tiene que corresponder a un objeto espacial.\n",
    "5. Guarda tu `DataFrame` con el nombre de `near_earth_objects-january_february_1995-raw.csv`.\n",
    "\n",
    "> **Nota**: En este momento no te preocupes por explorar o limpiar tu dataset. Eso lo haremos en la siguiente sesión. Lo que sí tienes que asegurarte es de normalizar tus datos antes de convertirlos en `DataFrame`.\n",
    "\n",
    "¡Mucha suerte!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
